{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Playing with `claude-v1.3-100k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import anthropic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import openai\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = anthropic.Client(api_key=os.environ['ANTHROPIC_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_claude(prommpt):\n",
    "    response = client.completion_stream(\n",
    "        prompt=f\"{anthropic.HUMAN_PROMPT} %s {anthropic.AI_PROMPT}\"\n",
    "        % prommpt,\n",
    "        stop_sequences=[anthropic.HUMAN_PROMPT],\n",
    "        max_tokens_to_sample=6000,\n",
    "        model=\"claude-v1.3-100k\",\n",
    "        stream=False,\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load GPTs are GPTs paper\n",
    "\n",
    "with open('./gpts_are_gpts/main.tex', 'r') as f:\n",
    "    paper_1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_r = query_claude(\"summerize the paper below: \\n\\n\" + paper_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = []\n",
    "\n",
    "for data in gen_r:\n",
    "    response = data\n",
    "    responses.append(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here is a summary of the paper:\n",
      "\n",
      "- The paper investigates the potential impact of large language models (LLMs) like GPT on the U.S. labor market. The authors propose a new rubric to assess LLM capabilities and their potential effects on jobs. \n",
      "\n",
      "- Using the rubric, the authors find that around 80% of U.S. workers could have at least 10% of their work tasks affected by LLMs, while 19% may see at least 50% of their tasks impacted. The impacts span all wage levels, with higher-income jobs potentially facing greater exposure. \n",
      "\n",
      "- The authors compare their rubric to previous studies on technology exposure. They find their measures are correlated with most other studies but explain 28-40% of the unexplained variance, indicating their rubric provides new insights.\n",
      "\n",
      "- The authors examine exposure by industry and find that information processing industries show high exposure, while manufacturing, agriculture, and mining demonstrate lower exposure. Recent productivity growth appears uncorrelated with overall LLM exposure, suggesting future productivity gains from LLMs may not worsen cost disease effects.\n",
      "\n",
      "- The authors argue that LLMs exhibit traits of general-purpose technologies, indicating substantial and hard to predict economic, social, and policy implications. If \"GPTs are GPTs,\" LLMs' development and application may challenge policymakers. \n",
      "\n",
      "- The paper's key contributions are a set of LLM impact measurements and demonstrating using LLMs to develop such measurements. The results show the general-purpose potential of LLMs.\n",
      "\n",
      "- Limitations include subjective judgments in the rubric, limitations of using GPT-4 for measurement, lacks expertise in task interpretation, is forward-looking, and has sources of disagreement in annotations. Future work could examine LLM adoption, compare theoretical and practical performance, study other countries, and consider vision capabilities.\n",
      "\n",
      "- In conclusion, the study shows LLMs could significantly affect many U.S. jobs. Policymakers should consider societal preparedness for the economic impact of LLMs and complementary technologies they enable. Further research on LLM's implications for jobs, inequality, and skills is needed.\n"
     ]
    }
   ],
   "source": [
    "print(responses[0]['completion'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
